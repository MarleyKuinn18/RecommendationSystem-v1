{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">A Recommendation System is an engine that operates like a filter predicting the preferences of a group of items for a user amongst a universal set of items, and recommends the closest ‘x’ items based on various parameters.\n",
    "![Recommendation System Image](https://miro.medium.com/max/640/1*D8qyeXxlbHFUlpZtfjvM7Q.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import re\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytreebank\n",
    "import sys\n",
    "\n",
    "dataset = pytreebank.load_sst()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(sys.path[0], 'sst_{}.txt')\n",
    "for category in ['train', 'test', 'dev']:\n",
    "    with open(out_path.format(category), 'w') as outfile:\n",
    "        for item in dataset[category]:\n",
    "            outfile.write(\"__label__{}\\t{}\\n\".format(\n",
    "                item.to_labeled_lines()[0][0] + 1,\n",
    "                item.to_labeled_lines()[0][1]\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('sst_train.txt', sep='\\t',header=None, names=['sentiment_label', 'sentence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['vader_score'] = train[\"sentence\"].apply(lambda Description: sid.polarity_scores(Description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['compound'] = train['vader_score'].apply(lambda score_dict: score_dict['compound'])\n",
    "train['vader_pred'] = pd.cut(train['compound'], bins=5, labels=[1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Book Reviews Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A15Q7ABIU9O9YZ</td>\n",
       "      <td>60554800</td>\n",
       "      <td>Larry Scantlebury</td>\n",
       "      <td>This is my first GM Ford book and I will read ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Red Tide: A Novel (Ford, G. M.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUIJDXNYVTEA8</td>\n",
       "      <td>60554800</td>\n",
       "      <td>Les Stockton</td>\n",
       "      <td>I liked the story.  I thought the book added a...</td>\n",
       "      <td>4</td>\n",
       "      <td>Red Tide: A Novel (Ford, G. M.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A20N5GOON55TE9</td>\n",
       "      <td>60554800</td>\n",
       "      <td>lila</td>\n",
       "      <td>As always, G.M. Ford does not disappoint. I st...</td>\n",
       "      <td>5</td>\n",
       "      <td>Red Tide: A Novel (Ford, G. M.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1CT8ENDZSYTX3</td>\n",
       "      <td>60554800</td>\n",
       "      <td>Lisa B.</td>\n",
       "      <td>I love Ford's Leo Waterman series and the firs...</td>\n",
       "      <td>3</td>\n",
       "      <td>Red Tide: A Novel (Ford, G. M.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2SI6BNK5SWSMD</td>\n",
       "      <td>60554800</td>\n",
       "      <td>L. J. Roberts</td>\n",
       "      <td>It was nice to see Corso working with the poli...</td>\n",
       "      <td>3</td>\n",
       "      <td>Red Tide: A Novel (Ford, G. M.)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID      asin       reviewerName  \\\n",
       "0  A15Q7ABIU9O9YZ  60554800  Larry Scantlebury   \n",
       "1   AUIJDXNYVTEA8  60554800       Les Stockton   \n",
       "2  A20N5GOON55TE9  60554800               lila   \n",
       "3  A1CT8ENDZSYTX3  60554800            Lisa B.   \n",
       "4  A2SI6BNK5SWSMD  60554800      L. J. Roberts   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  This is my first GM Ford book and I will read ...        3   \n",
       "1  I liked the story.  I thought the book added a...        4   \n",
       "2  As always, G.M. Ford does not disappoint. I st...        5   \n",
       "3  I love Ford's Leo Waterman series and the firs...        3   \n",
       "4  It was nice to see Corso working with the poli...        3   \n",
       "\n",
       "                             title  \n",
       "0  Red Tide: A Novel (Ford, G. M.)  \n",
       "1  Red Tide: A Novel (Ford, G. M.)  \n",
       "2  Red Tide: A Novel (Ford, G. M.)  \n",
       "3  Red Tide: A Novel (Ford, G. M.)  \n",
       "4  Red Tide: A Novel (Ford, G. M.)  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Amazon Book Reviews.csv', usecols=[0,1,2,4,5,9])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = list(data['reviewText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('rslp')\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "nltk.download('stopwords')\n",
    "en_stopwords = set(stopwords.words('english'))\n",
    "ps = nltk.stem.RSLPStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCleanComment(review):\n",
    "    review = str(review)\n",
    "    review = review.lower()\n",
    "    review = review.replace('\"','')\n",
    "    review = review.replace(';','')\n",
    "    review = review.replace('_','')\n",
    "    review = review.replace('-','')\n",
    "    review = review.replace(',','')\n",
    "    review = re.sub('\\d', '', review)\n",
    "    tokens = tokenizer.tokenize(review)\n",
    "    new_tokens = [i for i in tokens if i not in en_stopwords]\n",
    "    stemmed_tokens = [ps.stem(i) for i in new_tokens]\n",
    "    \n",
    "    cleaned_review = ' '.join(stemmed_tokens)\n",
    "    return cleaned_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_reviews = [getCleanComment(i) for i in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['preprocessed_reviews'] = preprocessed_reviews\n",
    "data['vader_score'] = data[\"preprocessed_reviews\"].apply(lambda Description: sid.polarity_scores(Description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['compound'] = data['vader_score'].apply(lambda score_dict: score_dict['compound'])\n",
    "data['vader_pred'] = pd.cut(data['compound'], bins=5, labels=[1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "deselectlist =['reviewerID', 'asin' , 'title', 'reviewerName', 'reviewText', 'overall', 'vader_pred']\n",
    "data.loc[:,deselectlist].to_csv('newAmazonBooksRatings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Irrelevant Users using Link Analysis\n",
    "> ### What is Link Analysis\n",
    "Link analysis is the process of investigating social structures by the use of networks and graphs.\n",
    "To help with the use case we are trying to solve, link analysis helps in the following ways:\n",
    "> - Identifying anomaly nodes of a network (irrelevant users) who can be turned off to refine produced set of recommendations\n",
    "> - Predicting new links on already built social network to interrelate a new product with older ones having similar features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Amazon Book Reviews.csv')\n",
    "data.head()\n",
    "print(type(data))\n",
    "df = pd.DataFrame(data, columns = ['reviewerID', 'asin', 'title', 'reviewerName', 'helpful', 'reviewText', 'overall', 'summary', 'unixReviewTime', 'reviewTime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unweighted graph (visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unweighted graph (visualization)\n",
    "\n",
    "G = nx.Graph() \n",
    "for i in range(len(df)):\n",
    "    for j in range(len(df)):\n",
    "        if i!=j and df['title'][i] == df['title'][j]:\n",
    "            G.add_edge(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weighted graph\n",
    "\n",
    "\n",
    "# creating a multigraph able to contain multiple edges between nodes, \n",
    "# weight between edges being the mean of user ratings given by both\n",
    "\n",
    "GW = nx.MultiGraph() \n",
    "for i in range(len(df)):\n",
    "    for j in range(len(df)):\n",
    "        if i!=j and df['title'][i] == df['title'][j]:\n",
    "            GW.add_edge(df['reviewerID'][i],df['reviewerID'][j], weight = (int)(df['overall'][i]+df['overall'][j])/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing network with degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nx.draw(GW)\n",
    "plt.savefig(\"gw_path.jpg\",dpi=399)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.info(GW)) # same node for repeated user\n",
    "print(nx.info(G)) # different node for repeated user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_node_list = sorted(GW.degree, key=lambda x: x[1], reverse=True)\n",
    "max_node_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_node_list[-1])\n",
    "max_node_list_unweighted = sorted(G.degree, key = lambda x: x[1], reverse=True)\n",
    "print(max_node_list_unweighted[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing network by betweenness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(G)\n",
    "betCent = nx.betweenness_centrality(G, normalized=True, endpoints=True)\n",
    "node_color = [200.0 * G.degree(v) for v in G]\n",
    "node_size =  [v * 100 for v in betCent.values()]\n",
    "plt.figure(figsize=(8,8))\n",
    "nx.draw_networkx(G, pos=pos, with_labels=False,\n",
    "                 node_color=node_color,\n",
    "                 node_size=node_size )\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.average_clustering(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_dict = nx.triangles(G)\n",
    "dict(sorted(forward_dict.items(), key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = nx.google_matrix(GW, alpha = 0.89)\n",
    "#print(gm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding min page rank nodes from graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = nx.pagerank_numpy(G) # will return dict of user node page ranks\n",
    "#print(pr)\n",
    "# finding min page rank nodes from graph\n",
    "minval = min(pr.values())\n",
    "res = [k for k, v in pr.items() if v==minval]\n",
    "#print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Irrelevant users (based on page rank scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# irrelevant users (based on page rank scores) ->\n",
    "irrelevant_users = df.iloc[3:11,['reviewerID','reviewerName']]\n",
    "print(irrelevant_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prw = nx.pagerank_numpy(GW)\n",
    "minvalw = min(prw.values())\n",
    "resw = [k for k, v in prw.items() if v==minvalw]\n",
    "print(resw) # min page rank nodes in weighted, multi graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GW.degree('A1RREZ3HGOVT4D') # degree of min page rank node in weighted, multi graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.degree(3) # degree of min page rank node in unweighted graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing page ranks of important nodes for weighted graph ->\n",
    "\n",
    "print(prw.get('AFVQZQ8PW0L')) # node with max edges\n",
    "print(prw.get('A1RREZ3HGOVT4D')) # node with min page rank\n",
    "print(prw.get('A1W0Z6DWSQAFHN')) # node with min edges\n",
    "\n",
    "# nodes with min degree in graph are necessarily not anomalous nodes according to the page rank algorithm\n",
    "# an inference can be that newer users on a platform providing ratings may have less degree in the product\n",
    "# social network, but will not be directly treated as anomalies based on their usage pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing irrelevant users from the newAmazonBooksRatings dataset WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "from sklearn.metrics import *\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering using SVD\n",
    "> ### What is Collaborative Filtering\n",
    "Collaborative filtering technique is based on the idea that users that preferred certain items in the past are likely to agree again in the future. It filters out products that a user might prefer on the basis of activity by similar users.\n",
    "> ### What is SVD\n",
    "SVD is Singular Vector Decomposition. What it does is that it decomposes a matrix into constituent arrays of feature vectors corresponding to each row and each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "ratings_data = pd.read_csv(\"newAmazonBooksRatings.csv\", usecols = [0,1,2,5,6], header=0, names = [\"user_id\", \"book_id\", \"book_name\", \"user_rating\", \"sentiment_rating\"])\n",
    "ratings_data = ratings_data.assign(newUserId = ratings_data['user_id'].astype('category').cat.codes)\n",
    "ratings_data = ratings_data.assign(newBookId = ratings_data['book_id'].astype('category').cat.codes)\n",
    "newRatingCol = ratings_data.loc[:, \"user_rating\":\"sentiment_rating\"]\n",
    "ratings_data[\"mean_rating\"] = newRatingCol.mean(axis=1)\n",
    "ratings_data.drop([\"user_id\",\"book_id\", \"user_rating\", \"sentiment_rating\"], axis=1, inplace=True)\n",
    "cols = [\"newBookId\",\"book_name\"]\n",
    "books = ratings_data[cols].copy()\n",
    "books.drop_duplicates(inplace=True)\n",
    "books = books.reset_index(drop=True)\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "train_data = Dataset.load_from_df(ratings_data[[\"newUserId\", \"newBookId\", \"mean_rating\"]], reader)\n",
    "trainset = train_data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "svd = SVD(n_factors=100, n_epochs=5, biased=True, random_state=15, verbose=True)\n",
    "results = cross_validate(svd, train_data, measures=['RMSE', 'MAE'], cv=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estSort(pred):\n",
    "    return pred.est\n",
    "def recommend_books(user_id, num_recommendations) :\n",
    "    predictions = []\n",
    "    for x in pd.unique(ratings_data['newBookId']):\n",
    "        predictions.append(svd.predict(uid=0, iid=x))\n",
    "    predictions.sort(key = estSort, reverse=True)\n",
    "    recommendations = [x.iid for x in predictions[:num_recommendations]]\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_indices=recommend_books(user_id=101, num_recommendations=7)\n",
    "recommendations = [books.values[x] for x in book_indices]\n",
    "recommendations = DataFrame(recommendations, columns=[\"book_id\", \"book_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings = ratings_data.pivot(\n",
    "    index='newUserId',\n",
    "    columns='newBookId',\n",
    "    values='mean_rating'\n",
    ").fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = movie_ratings.values\n",
    "from scipy.sparse.linalg import svds\n",
    "U, sigma, Vt = svds(R, k = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = np.diag(sigma)\n",
    "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) \n",
    "#print(all_user_predicted_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_books(predictions, user_index, books, org_matrix, num_recommendations=5):\n",
    "    sorted_books = (-predictions[user_index]).argsort()\n",
    "    boolArr = (org_matrix[user_index] == 0)\n",
    "    unknown_sorted_books = [x for x in sorted_books if boolArr[x]]\n",
    "    recommendations = [books[x] for x in unknown_sorted_books][:num_recommendations]               \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_books = recommend_books(all_user_predicted_ratings, 1, books.values, R, 7)\n",
    "top_books = DataFrame(top_books, columns=[\"book_id\", \"book_name\"])\n",
    "print(top_books)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_similarity(list_1, list_2):\n",
    "    cos_sim = dot(list_1, list_2) / (norm(list_1) * norm(list_2))\n",
    "    return cos_sim\n",
    "\n",
    "def top_cosine_similarity(data, book_id, top_n=10):\n",
    "    index = book_id - 1 \n",
    "    book_row = data[index, :]\n",
    "    similarity_values = np.zeros(shape=[data.shape[0]-1,2])\n",
    "    k=0\n",
    "    for i in range(data.shape[0]):\n",
    "        if i != index :\n",
    "            val = cosine_similarity(book_row, data[i, :])\n",
    "            similarity_values[k] = np.array([i, val])\n",
    "            k = k + 1\n",
    "            \n",
    "    sort_indices = np.argsort(-similarity_values[:, 1])\n",
    "    return sort_indices[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = input(\"Enter your favorite book id: \")\n",
    "val = int(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_book_indices = top_cosine_similarity(Vt.T, val)\n",
    "similar_books = [books.values[x] for x in top_book_indices]\n",
    "similar_books = DataFrame(similar_books, columns=[\"book_id\", \"book_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Books similar to \"+books.book_name[val-1]+\" are:\\n\")\n",
    "print(similar_books)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

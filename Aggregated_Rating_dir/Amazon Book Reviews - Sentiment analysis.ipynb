{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A15Q7ABIU9O9YZ</td>\n",
       "      <td>60554800</td>\n",
       "      <td>Larry Scantlebury</td>\n",
       "      <td>[2,3]</td>\n",
       "      <td>This is my first GM Ford book and I will read ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Let's keep it real, not personal</td>\n",
       "      <td>1127606400</td>\n",
       "      <td>09 25, 2005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUIJDXNYVTEA8</td>\n",
       "      <td>60554800</td>\n",
       "      <td>Les Stockton</td>\n",
       "      <td>[0,2]</td>\n",
       "      <td>I liked the story.  I thought the book added a...</td>\n",
       "      <td>4</td>\n",
       "      <td>I liked it</td>\n",
       "      <td>1361923200</td>\n",
       "      <td>02 27, 2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A20N5GOON55TE9</td>\n",
       "      <td>60554800</td>\n",
       "      <td>lila</td>\n",
       "      <td>[0,2]</td>\n",
       "      <td>As always, G.M. Ford does not disappoint. I st...</td>\n",
       "      <td>5</td>\n",
       "      <td>Good reading</td>\n",
       "      <td>1366761600</td>\n",
       "      <td>04 24, 2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1CT8ENDZSYTX3</td>\n",
       "      <td>60554800</td>\n",
       "      <td>Lisa B.</td>\n",
       "      <td>[1,2]</td>\n",
       "      <td>I love Ford's Leo Waterman series and the firs...</td>\n",
       "      <td>3</td>\n",
       "      <td>Science Fiction or Mystery?</td>\n",
       "      <td>1122249600</td>\n",
       "      <td>07 25, 2005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2SI6BNK5SWSMD</td>\n",
       "      <td>60554800</td>\n",
       "      <td>L. J. Roberts</td>\n",
       "      <td>[2,2]</td>\n",
       "      <td>It was nice to see Corso working with the poli...</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5 stars - Needed a better end.</td>\n",
       "      <td>1113004800</td>\n",
       "      <td>04 9, 2005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID      asin       reviewerName helpful  \\\n",
       "0  A15Q7ABIU9O9YZ  60554800  Larry Scantlebury   [2,3]   \n",
       "1   AUIJDXNYVTEA8  60554800       Les Stockton   [0,2]   \n",
       "2  A20N5GOON55TE9  60554800               lila   [0,2]   \n",
       "3  A1CT8ENDZSYTX3  60554800            Lisa B.   [1,2]   \n",
       "4  A2SI6BNK5SWSMD  60554800      L. J. Roberts   [2,2]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  This is my first GM Ford book and I will read ...        3   \n",
       "1  I liked the story.  I thought the book added a...        4   \n",
       "2  As always, G.M. Ford does not disappoint. I st...        5   \n",
       "3  I love Ford's Leo Waterman series and the firs...        3   \n",
       "4  It was nice to see Corso working with the poli...        3   \n",
       "\n",
       "                            summary  unixReviewTime   reviewTime  sentiment  \n",
       "0  Let's keep it real, not personal      1127606400  09 25, 2005          0  \n",
       "1                        I liked it      1361923200  02 27, 2013          1  \n",
       "2                      Good reading      1366761600  04 24, 2013          1  \n",
       "3       Science Fiction or Mystery?      1122249600  07 25, 2005          0  \n",
       "4  3.5 stars - Needed a better end.      1113004800   04 9, 2005          0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Amazon Book Reviews.csv')\n",
    "#data['sentiment'] = data.apply(lambda x: -1 if x['overall'] <= 2 else 0 if x['overall'] == 3 else 1, axis = 1)\n",
    "data['sentiment'] = data.apply(lambda x: 0 if x['overall'] <= 3 else 1, axis = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = list(data['reviewText'])\n",
    "sent = list(data['sentiment'])\n",
    "comment_train, comment_test, sent_train, sent_test = train_test_split(comment, sent, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "nltk.download('stopwords')\n",
    "en_stopwords = set(stopwords.words('english'))\n",
    "#ps = PorterStemmer()\n",
    "ps = nltk.stem.RSLPStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCleanComment(review):\n",
    "    review = str(review)\n",
    "    review = review.lower()\n",
    "    review = review.replace('\"','')\n",
    "    review = review.replace(';','')\n",
    "    review = review.replace('_','')\n",
    "    review = review.replace('-','')\n",
    "    review = review.replace(',','')\n",
    "    review = re.sub('\\d', '', review)\n",
    "    tokens = tokenizer.tokenize(review)\n",
    "    new_tokens = [i for i in tokens if i not in en_stopwords]\n",
    "    stemmed_tokens = [ps.stem(i) for i in new_tokens]\n",
    "    \n",
    "    cleaned_review = ' '.join(stemmed_tokens)\n",
    "    return cleaned_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_train = [getCleanComment(i) for i in comment_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5948, 31695)\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "comment_train_vec = cv.fit_transform(comment_train)\n",
    "print(comment_train_vec.shape)\n",
    "#cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(comment_train_vec,sent_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_test = [getCleanComment(i) for i in comment_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1488, 31695)\n"
     ]
    }
   ],
   "source": [
    "comment_test_vec = cv.transform(comment_test)\n",
    "print(comment_test_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_prediction = mnb.predict(comment_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8057795698924731"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(sent_test, sentiment_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernaulli NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(comment_train_vec,sent_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7439516129032258"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_prediction_bnb = bnb.predict(comment_test_vec)\n",
    "accuracy_score(sent_test, sentiment_prediction_bnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(dual=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "lsvm = LinearSVC(dual=False)\n",
    "lsvm.fit(comment_train_vec,sent_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7869623655913979"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_prediction_svm = lsvm.predict(comment_test_vec)\n",
    "accuracy_score(sent_test, sentiment_prediction_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigram + Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5948, 448955)\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,2))\n",
    "comment_train_vec = cv.fit_transform(comment_train)\n",
    "print(comment_train_vec.shape)\n",
    "#cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(comment_train_vec,sent_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1488, 448955)\n"
     ]
    }
   ],
   "source": [
    "comment_test = [getCleanComment(i) for i in comment_test]\n",
    "comment_test_vec = cv.transform(comment_test)\n",
    "print(comment_test_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7573924731182796"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "sentiment_prediction = mnb.predict(comment_test_vec)\n",
    "accuracy_score(sent_test, sentiment_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernaulli NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7553763440860215"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(comment_train_vec,sent_train)\n",
    "sentiment_prediction_bnb = bnb.predict(comment_test_vec)\n",
    "accuracy_score(sent_test, sentiment_prediction_bnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.803763440860215"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "lsvm = LinearSVC(dual=False)\n",
    "lsvm.fit(comment_train_vec,sent_train)\n",
    "sentiment_prediction_svm = lsvm.predict(comment_test_vec)\n",
    "accuracy_score(sent_test, sentiment_prediction_svm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

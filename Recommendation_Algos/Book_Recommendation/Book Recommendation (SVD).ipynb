{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "from sklearn.metrics import *\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Get Dataset </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      newBookId                                          book_name\n",
      "0            19                                           Red Tide\n",
      "11           20                                      No Man's Land\n",
      "36           21                                   Day of Atonement\n",
      "61           22  he Jaguar Knights: A Chronicle of the King's B...\n",
      "72           23                                   The Last Goodbye\n",
      "...         ...                                                ...\n",
      "7268        165  The Brother of Jesus: The Dramatic Story &amp;...\n",
      "7279        166                               The Great Unraveling\n",
      "7331        167        By the Shores of Silver Lake (Little House)\n",
      "7353        168                     The Long Winter (Little House)\n",
      "7383        169                A Good Yarn (Blossom Street, No. 2)\n",
      "\n",
      "[266 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from pandas import DataFrame\n",
    "ratings_data = pd.read_csv(\"./Books Dataset/Amazon Book Reviews.csv\", usecols = [0,1,2,6], header=0, names = [\"user_id\", \"book_id\", \"book_name\", \"rating\"])\n",
    "ratings_data = ratings_data.assign(newUserId = ratings_data['user_id'].astype('category').cat.codes)\n",
    "ratings_data = ratings_data.assign(newBookId = ratings_data['book_id'].astype('category').cat.codes)\n",
    "ratings_data.drop([\"user_id\",\"book_id\"], axis=1, inplace=True)\n",
    "cols = [\"newBookId\",\"book_name\"]\n",
    "books = ratings_data[cols].copy()\n",
    "books.drop_duplicates(inplace=True)\n",
    "print(books)\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "train_data = Dataset.load_from_df(ratings_data[['newUserId', 'newBookId', 'rating']], reader)\n",
    "trainset = train_data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> SVD (Surprise lib) </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Evaluating RMSE, MAE of algorithm SVD on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    1.0299  1.0298  1.0642  1.0413  0.0162  \n",
      "MAE (testset)     0.8104  0.8078  0.8456  0.8212  0.0173  \n",
      "Fit time          0.10    0.08    0.09    0.09    0.00    \n",
      "Test time         0.02    0.01    0.02    0.02    0.00    \n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "svd = SVD(n_factors=100, n_epochs=5, biased=True, random_state=15, verbose=True)\n",
    "results = cross_validate(svd, train_data, measures=['RMSE', 'MAE'], cv=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n"
     ]
    }
   ],
   "source": [
    "model=svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estSort(pred):\n",
    "    return pred.est\n",
    "def recommend_books(user_id) :\n",
    "    predictions = []\n",
    "    for x in pd.unique(ratings_data['newBookId']):\n",
    "        predictions.append(svd.predict(uid=0, iid=x))\n",
    "    predictions.sort(key = estSort, reverse=True)\n",
    "    recommendations = [x.iid for x in predictions[:7]]\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_indices=recommend_books(user_id=0)\n",
    "recommendations = [books.values[x] for x in book_indices]\n",
    "recommendations = DataFrame(recommendations, columns=[\"book_id\", \"book_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   book_id                                          book_name\n",
      "0       30                The Stingray Shuffle (Serge Storms)\n",
      "1       96  A Year with C. S. Lewis: Daily Readings from H...\n",
      "2      119  A Crack in the Edge of the World: America and ...\n",
      "3       44                                        Goldengrove\n",
      "4      119  A Crack in the Edge of the World: America and ...\n",
      "5      119  A Crack in the Edge of the World: America and ...\n",
      "6        9                                      Deadly Double\n"
     ]
    }
   ],
   "source": [
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> SVD (Scipy lib) </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings = ratings_data.pivot(\n",
    "    index='newUserId',\n",
    "    columns='newBookId',\n",
    "    values='rating'\n",
    ").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = movie_ratings.values\n",
    "from scipy.sparse.linalg import svds\n",
    "U, sigma, Vt = svds(R, k = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.75112507e-03 -2.89592643e-03 -1.32330333e-03 ...  1.00985774e-03\n",
      "   1.54498895e-03 -4.99066258e-03]\n",
      " [-1.13728763e-02  1.70883417e-02 -6.67785829e-03 ...  2.89990740e-02\n",
      "  -3.64796942e-02  5.35367015e-03]\n",
      " [-5.27405513e-04 -3.33739289e-04 -5.90329619e-04 ...  3.92585431e-04\n",
      "  -3.79413993e-04 -2.17999577e-05]\n",
      " ...\n",
      " [-3.40141125e-03 -6.65392984e-04  1.07192237e-02 ...  2.08001877e-02\n",
      "  -1.51528338e-02 -2.57933247e-04]\n",
      " [-2.63702757e-03 -1.66869645e-03 -2.95164809e-03 ...  1.96292715e-03\n",
      "  -1.89706997e-03 -1.08999789e-04]\n",
      " [ 8.90993930e-04  2.16761741e-04  1.14542531e-04 ... -3.47980808e-04\n",
      "   2.26759025e-04 -5.62255188e-04]]\n"
     ]
    }
   ],
   "source": [
    "sigma = np.diag(sigma)\n",
    "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) \n",
    "print(all_user_predicted_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_books(predictions, user_index, books, org_matrix, num_recommendations=5):\n",
    "    sorted_books = (-predictions[user_index]).argsort()\n",
    "    boolArr = (org_matrix[user_index] == 0)\n",
    "    unknown_sorted_books = [x for x in sorted_books if boolArr[x]]\n",
    "    recommendations = [books[x] for x in unknown_sorted_books][:num_recommendations]               \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   book_id                                          book_name\n",
      "0       26  The Intelligent Investor: The Definitive Book ...\n",
      "1       23                                   The Last Goodbye\n",
      "2       20                                      No Man's Land\n",
      "3       21                                   Day of Atonement\n"
     ]
    }
   ],
   "source": [
    "top_books = recommend_books(all_user_predicted_ratings, 1, books.values, R, 4)\n",
    "top_books = DataFrame(top_books, columns=[\"book_id\", \"book_name\"])\n",
    "print(top_books)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Similar books </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_similarity(list_1, list_2):\n",
    "    cos_sim = dot(list_1, list_2) / (norm(list_1) * norm(list_2))\n",
    "    return cos_sim\n",
    "\n",
    "def top_cosine_similarity(data, book_id, top_n=10):\n",
    "    index = book_id - 1 \n",
    "    book_row = data[index, :]\n",
    "    similarity_values = np.zeros(shape=[data.shape[0]-1,2])\n",
    "    k=0\n",
    "    for i in range(data.shape[0]):\n",
    "        if i != index :\n",
    "            val = cosine_similarity(book_row, data[i, :])\n",
    "            similarity_values[k] = np.array([i, val])\n",
    "            k = k + 1\n",
    "            \n",
    "    sort_indices = np.argsort(-similarity_values[:, 1])\n",
    "    return sort_indices[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_book_indices = top_cosine_similarity(Vt.T, 13, 4)\n",
    "similar_books = [books.values[x] for x in top_book_indices]\n",
    "similar_books = DataFrame(similar_books, columns=[\"book_id\", \"book_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books similar to No Man's Landare:\n",
      "\n",
      "   book_id                                          book_name\n",
      "0       26  The Intelligent Investor: The Definitive Book ...\n",
      "1       20                                      No Man's Land\n",
      "2       23                                   The Last Goodbye\n",
      "3       19                                           Red Tide\n"
     ]
    }
   ],
   "source": [
    "print(\"Books similar to \"+books.book_name[12]+\"are:\\n\")\n",
    "print(similar_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "from sklearn.metrics import *\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Get Dataset </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      newBookId                            book_name\n",
      "0            19                             Red Tide\n",
      "1            19                             Red Tide\n",
      "2            19                             Red Tide\n",
      "3            19                             Red Tide\n",
      "4            19                             Red Tide\n",
      "...         ...                                  ...\n",
      "7431        169  A Good Yarn (Blossom Street, No. 2)\n",
      "7432        169  A Good Yarn (Blossom Street, No. 2)\n",
      "7433        169  A Good Yarn (Blossom Street, No. 2)\n",
      "7434        169  A Good Yarn (Blossom Street, No. 2)\n",
      "7435        169  A Good Yarn (Blossom Street, No. 2)\n",
      "\n",
      "[7436 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from pandas import DataFrame\n",
    "ratings_data = pd.read_csv(\"./Books Dataset/Amazon Book Reviews.csv\", usecols = [0,1,2,6], header=0, names = [\"user_id\", \"book_id\", \"book_name\", \"rating\"])\n",
    "ratings_data = ratings_data.assign(newUserId = ratings_data['user_id'].astype('category').cat.codes)\n",
    "ratings_data = ratings_data.assign(newBookId = ratings_data['book_id'].astype('category').cat.codes)\n",
    "ratings_data.drop([\"user_id\",\"book_id\"], axis=1, inplace=True)\n",
    "cols = [\"newBookId\",\"book_name\"]\n",
    "books = ratings_data[cols].copy()\n",
    "print(books)\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "train_data = Dataset.load_from_df(ratings_data[['newUserId', 'newBookId', 'rating']], reader)\n",
    "trainset = train_data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> SVD (Surprise lib) </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Evaluating RMSE, MAE of algorithm SVD on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    1.0395  1.0578  1.0298  1.0424  0.0116  \n",
      "MAE (testset)     0.8170  0.8333  0.8123  0.8209  0.0090  \n",
      "Fit time          0.39    0.23    0.25    0.29    0.07    \n",
      "Test time         0.08    0.04    0.05    0.06    0.02    \n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "svd = SVD(n_factors=100, n_epochs=5, biased=True, random_state=15, verbose=True)\n",
    "results = cross_validate(svd, train_data, measures=['RMSE', 'MAE'], cv=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n"
     ]
    }
   ],
   "source": [
    "model=svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estSort(pred):\n",
    "    return pred.est\n",
    "def recommend_books(user_id) :\n",
    "    predictions = []\n",
    "    for x in pd.unique(ratings_data['newBookId']):\n",
    "        predictions.append(svd.predict(uid=0, iid=x))\n",
    "    predictions.sort(key = estSort, reverse=True)\n",
    "    recommendations = [x.iid for x in predictions[:7]]\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_indices=recommend_books(user_id=0)\n",
    "recommendations = [books.values[x] for x in book_indices]\n",
    "recommendations = DataFrame(recommendations, columns=[\"book_id\", \"book_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   book_id                                          book_name\n",
      "0       20                                      No Man's Land\n",
      "1       24  The Secret Life of Lobsters: How Fishermen and...\n",
      "2       26  The Intelligent Investor: The Definitive Book ...\n",
      "3       20                                      No Man's Land\n",
      "4       26  The Intelligent Investor: The Definitive Book ...\n",
      "5       26  The Intelligent Investor: The Definitive Book ...\n",
      "6       23                                   The Last Goodbye\n"
     ]
    }
   ],
   "source": [
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> SVD (Scipy lib) </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings = ratings_data.pivot(\n",
    "    index='newUserId',\n",
    "    columns='newBookId',\n",
    "    values='rating'\n",
    ").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = movie_ratings.values\n",
    "from scipy.sparse.linalg import svds\n",
    "U, sigma, Vt = svds(R, k = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.75112507e-03 -2.89592643e-03 -1.32330333e-03 ...  1.00985774e-03\n",
      "   1.54498895e-03 -4.99066258e-03]\n",
      " [-1.13728763e-02  1.70883417e-02 -6.67785829e-03 ...  2.89990740e-02\n",
      "  -3.64796942e-02  5.35367015e-03]\n",
      " [-5.27405513e-04 -3.33739289e-04 -5.90329619e-04 ...  3.92585431e-04\n",
      "  -3.79413993e-04 -2.17999577e-05]\n",
      " ...\n",
      " [-3.40141125e-03 -6.65392984e-04  1.07192237e-02 ...  2.08001877e-02\n",
      "  -1.51528338e-02 -2.57933247e-04]\n",
      " [-2.63702757e-03 -1.66869645e-03 -2.95164809e-03 ...  1.96292715e-03\n",
      "  -1.89706997e-03 -1.08999789e-04]\n",
      " [ 8.90993930e-04  2.16761741e-04  1.14542531e-04 ... -3.47980808e-04\n",
      "   2.26759025e-04 -5.62255188e-04]]\n"
     ]
    }
   ],
   "source": [
    "sigma = np.diag(sigma)\n",
    "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) \n",
    "print(all_user_predicted_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_books(predictions, user_index, books, org_matrix, num_recommendations=5):\n",
    "    sorted_books = (-predictions[user_index]).argsort()\n",
    "    boolArr = (org_matrix[user_index] == 0)\n",
    "    unknown_sorted_books = [x for x in sorted_books if boolArr[x]]\n",
    "    recommendations = [books[x] for x in unknown_sorted_books][:num_recommendations]               \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   book_id                                          book_name\n",
      "0       26  The Intelligent Investor: The Definitive Book ...\n",
      "1       22  he Jaguar Knights: A Chronicle of the King's B...\n",
      "2       26  The Intelligent Investor: The Definitive Book ...\n",
      "3       19                                           Red Tide\n",
      "4       22  he Jaguar Knights: A Chronicle of the King's B...\n",
      "5       20                                      No Man's Land\n",
      "6       23                                   The Last Goodbye\n"
     ]
    }
   ],
   "source": [
    "top_7_books = recommend_movies(all_user_predicted_ratings, 7, books.values, R, 7)\n",
    "top_7_books = DataFrame(top_7_books, columns=[\"book_id\", \"book_name\"])\n",
    "print(top_7_books)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Similar books </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_cosine_similarity(data, book_id, top_n=10):\n",
    "    index = book_id - 1 \n",
    "    book_row = data[index, :]\n",
    "    magnitude = np.sqrt(np.einsum('ij, ij -> i', data, data))\n",
    "    similarity = np.dot(book_row, data.T) / (magnitude[index] * magnitude)\n",
    "    sort_indexes = np.argsort(-similarity)\n",
    "    return sort_indexes[:top_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_book_indices = top_cosine_similarity(Vt.T, 13, 10)\n",
    "similar_books = [books.values[x] for x in top_book_indices]\n",
    "similar_books = DataFrame(similar_books, columns=[\"book_id\", \"book_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books similar to No Man's Landare:\n",
      "\n",
      "   book_id                                          book_name\n",
      "0       20                                      No Man's Land\n",
      "1       26  The Intelligent Investor: The Definitive Book ...\n",
      "2       20                                      No Man's Land\n",
      "3       23                                   The Last Goodbye\n",
      "4       19                                           Red Tide\n",
      "5       20                                      No Man's Land\n",
      "6       26  The Intelligent Investor: The Definitive Book ...\n",
      "7       21                                   Day of Atonement\n",
      "8       20                                      No Man's Land\n",
      "9       26  The Intelligent Investor: The Definitive Book ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Books similar to \"+books.book_name[12]+\"are:\\n\")\n",
    "print(similar_books)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
